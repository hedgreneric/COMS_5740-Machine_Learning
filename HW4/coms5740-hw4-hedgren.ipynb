{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW4 — Neural Network\n",
    "\n",
    "Eric Hedgren\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. For each problem below, state which dimensions \\( $d$, $d_H$, $d_o$ \\) are determined by the problem, and state the value of each of those dimensions. Similarly, state whether the activation function $g_H(·)$ or $g_o(·)$ is determined by the problem, and if it is determined, state what it should be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) One wants a neural network that takes a 32 × 32 RGB-format image and determines which alphanumeric letter (from ‘a’ through ‘z’ and ‘0’ through ‘9’) the image depicts.\n",
    "\n",
    "$d = 32 \\times 32 \\times 3 = 3,072$ (32 for each dimension and 3 for RGB)\n",
    "\n",
    "$d_H$ (design choice, not determined by the problem)\n",
    "\n",
    "$d_o = 36$ (determine which letter (26) or number (10) it is)\n",
    "\n",
    "$g_H(\\cdot) =$ ReLU\n",
    "\n",
    "$g_o(\\cdot) =$ multi-classification (determining which character it is)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Suppose that you are presented with a paragraph of 128 tokens given by a writer. One wants a network that determines whether the writer is happy or sad.\n",
    "\n",
    "$d = 128 \\times e$ (e is the size of the embedding vector)\n",
    "\n",
    "$d_H$ (design choice, not determined by the problem)\n",
    "\n",
    "$d_o = 1$ (output is sad or happy, aka binary)\n",
    "\n",
    "$g_H(\\cdot) =$ ReLU\n",
    "\n",
    "$g_o(\\cdot) =$ binary classification (determining happy or sad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) You want a neural network that predicts the future GPS coordinate pair of a watch given 20 past GPS coordinate pairs.\n",
    "\n",
    "$d = 20 \\times 2 = 40$ (longitude and latitude in each pair with 20 pairs)\n",
    "\n",
    "$d_H$ (design choice, not determined by the problem)\n",
    "\n",
    "$d_o = 2$ (output is single GPS coordinate pair)\n",
    "\n",
    "$g_H(\\cdot) =$ ReLU\n",
    "\n",
    "$g_o(\\cdot) =$ Linear regression (no activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Design a MLP neural network to solve the house price prediction problem (using the same data set we have been using for the first half of the semester). Take all 6 X features as the input and the house price as the output. Use no more than 3 hidden layers. Each hidden layer can have no more than 30 units. Use ReLU as the activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Show me your code (data loading & normalization, network structure, and training). Use the “NeuralNetwork.ipynb\" as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/Real_estate.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10000], Loss: 84.2255\n",
      "Epoch [20/10000], Loss: 49.1794\n",
      "Epoch [30/10000], Loss: 60.2709\n",
      "Epoch [40/10000], Loss: 105.7323\n",
      "Epoch [50/10000], Loss: 44.8935\n",
      "Epoch [60/10000], Loss: 19.8117\n",
      "Epoch [70/10000], Loss: 21.9490\n",
      "Epoch [80/10000], Loss: 18.7333\n",
      "Epoch [90/10000], Loss: 67.4945\n",
      "Epoch [100/10000], Loss: 49.8341\n",
      "Epoch [110/10000], Loss: 468.9529\n",
      "Epoch [120/10000], Loss: 85.5411\n",
      "Epoch [130/10000], Loss: 22.3485\n",
      "Epoch [140/10000], Loss: 43.0268\n",
      "Epoch [150/10000], Loss: 95.8775\n",
      "Epoch [160/10000], Loss: 19.1783\n",
      "Epoch [170/10000], Loss: 48.6521\n",
      "Epoch [180/10000], Loss: 135.5172\n",
      "Epoch [190/10000], Loss: 18.7864\n",
      "Epoch [200/10000], Loss: 14.3450\n",
      "Epoch [210/10000], Loss: 35.4837\n",
      "Epoch [220/10000], Loss: 43.4114\n",
      "Epoch [230/10000], Loss: 72.8155\n",
      "Epoch [240/10000], Loss: 12.9135\n",
      "Epoch [250/10000], Loss: 23.7288\n",
      "Epoch [260/10000], Loss: 17.8323\n",
      "Epoch [270/10000], Loss: 116.4304\n",
      "Epoch [280/10000], Loss: 26.4611\n",
      "Epoch [290/10000], Loss: 28.5395\n",
      "Epoch [300/10000], Loss: 20.3683\n",
      "Epoch [310/10000], Loss: 45.9492\n",
      "Epoch [320/10000], Loss: 3.4196\n",
      "Epoch [330/10000], Loss: 69.8744\n",
      "Epoch [340/10000], Loss: 12.8475\n",
      "Epoch [350/10000], Loss: 7.3669\n",
      "Epoch [360/10000], Loss: 36.5089\n",
      "Epoch [370/10000], Loss: 13.8678\n",
      "Epoch [380/10000], Loss: 11.7951\n",
      "Epoch [390/10000], Loss: 41.4531\n",
      "Epoch [400/10000], Loss: 19.9764\n",
      "Epoch [410/10000], Loss: 23.5978\n",
      "Epoch [420/10000], Loss: 15.5367\n",
      "Epoch [430/10000], Loss: 53.8309\n",
      "Epoch [440/10000], Loss: 32.8070\n",
      "Epoch [450/10000], Loss: 19.7710\n",
      "Epoch [460/10000], Loss: 77.1690\n",
      "Epoch [470/10000], Loss: 45.4759\n",
      "Epoch [480/10000], Loss: 25.7036\n",
      "Epoch [490/10000], Loss: 12.0674\n",
      "Epoch [500/10000], Loss: 22.7221\n",
      "Epoch [510/10000], Loss: 38.0664\n",
      "Epoch [520/10000], Loss: 22.4506\n",
      "Epoch [530/10000], Loss: 25.4834\n",
      "Epoch [540/10000], Loss: 14.9396\n",
      "Epoch [550/10000], Loss: 13.0995\n",
      "Epoch [560/10000], Loss: 10.7416\n",
      "Epoch [570/10000], Loss: 17.5725\n",
      "Epoch [580/10000], Loss: 23.1741\n",
      "Epoch [590/10000], Loss: 13.2901\n",
      "Epoch [600/10000], Loss: 36.2921\n",
      "Epoch [610/10000], Loss: 9.0030\n",
      "Epoch [620/10000], Loss: 16.2579\n",
      "Epoch [630/10000], Loss: 33.6077\n",
      "Epoch [640/10000], Loss: 82.2087\n",
      "Epoch [650/10000], Loss: 111.0696\n",
      "Epoch [660/10000], Loss: 26.4458\n",
      "Epoch [670/10000], Loss: 10.0319\n",
      "Epoch [680/10000], Loss: 9.3982\n",
      "Epoch [690/10000], Loss: 5.6680\n",
      "Epoch [700/10000], Loss: 85.6916\n",
      "Epoch [710/10000], Loss: 17.8577\n",
      "Epoch [720/10000], Loss: 33.1533\n",
      "Epoch [730/10000], Loss: 15.7089\n",
      "Epoch [740/10000], Loss: 20.4470\n",
      "Epoch [750/10000], Loss: 17.9453\n",
      "Epoch [760/10000], Loss: 11.2871\n",
      "Epoch [770/10000], Loss: 16.5971\n",
      "Epoch [780/10000], Loss: 45.6599\n",
      "Epoch [790/10000], Loss: 9.0220\n",
      "Epoch [800/10000], Loss: 30.2614\n",
      "Epoch [810/10000], Loss: 14.3142\n",
      "Epoch [820/10000], Loss: 31.1552\n",
      "Epoch [830/10000], Loss: 19.7958\n",
      "Epoch [840/10000], Loss: 11.2281\n",
      "Epoch [850/10000], Loss: 33.8411\n",
      "Epoch [860/10000], Loss: 9.6393\n",
      "Epoch [870/10000], Loss: 32.2463\n",
      "Epoch [880/10000], Loss: 9.2262\n",
      "Epoch [890/10000], Loss: 7.8204\n",
      "Epoch [900/10000], Loss: 13.5058\n",
      "Epoch [910/10000], Loss: 18.6159\n",
      "Epoch [920/10000], Loss: 0.7196\n",
      "Epoch [930/10000], Loss: 8.3117\n",
      "Epoch [940/10000], Loss: 5.9942\n",
      "Epoch [950/10000], Loss: 37.6270\n",
      "Epoch [960/10000], Loss: 8.8921\n",
      "Epoch [970/10000], Loss: 5.0070\n",
      "Epoch [980/10000], Loss: 16.0345\n",
      "Epoch [990/10000], Loss: 4.3546\n",
      "Epoch [1000/10000], Loss: 16.5910\n",
      "Epoch [1010/10000], Loss: 7.5913\n",
      "Epoch [1020/10000], Loss: 9.1352\n",
      "Epoch [1030/10000], Loss: 15.7901\n",
      "Epoch [1040/10000], Loss: 3.0662\n",
      "Epoch [1050/10000], Loss: 9.1686\n",
      "Epoch [1060/10000], Loss: 14.8749\n",
      "Epoch [1070/10000], Loss: 12.8734\n",
      "Epoch [1080/10000], Loss: 9.4459\n",
      "Epoch [1090/10000], Loss: 10.1262\n",
      "Epoch [1100/10000], Loss: 23.0543\n",
      "Epoch [1110/10000], Loss: 5.1134\n",
      "Epoch [1120/10000], Loss: 6.7618\n",
      "Epoch [1130/10000], Loss: 8.4861\n",
      "Epoch [1140/10000], Loss: 15.2663\n",
      "Epoch [1150/10000], Loss: 10.0697\n",
      "Epoch [1160/10000], Loss: 5.8815\n",
      "Epoch [1170/10000], Loss: 41.0600\n",
      "Epoch [1180/10000], Loss: 13.5069\n",
      "Epoch [1190/10000], Loss: 12.1433\n",
      "Epoch [1200/10000], Loss: 2.0968\n",
      "Epoch [1210/10000], Loss: 12.4814\n",
      "Epoch [1220/10000], Loss: 16.8374\n",
      "Epoch [1230/10000], Loss: 6.5457\n",
      "Epoch [1240/10000], Loss: 4.7655\n",
      "Epoch [1250/10000], Loss: 30.8314\n",
      "Epoch [1260/10000], Loss: 2.5605\n",
      "Epoch [1270/10000], Loss: 6.3188\n",
      "Epoch [1280/10000], Loss: 3.8329\n",
      "Epoch [1290/10000], Loss: 3.2310\n",
      "Epoch [1300/10000], Loss: 2.6349\n",
      "Epoch [1310/10000], Loss: 2.1079\n",
      "Epoch [1320/10000], Loss: 9.6090\n",
      "Epoch [1330/10000], Loss: 20.7639\n",
      "Epoch [1340/10000], Loss: 10.5553\n",
      "Epoch [1350/10000], Loss: 8.8058\n",
      "Epoch [1360/10000], Loss: 1.3397\n",
      "Epoch [1370/10000], Loss: 9.5388\n",
      "Epoch [1380/10000], Loss: 3.5179\n",
      "Epoch [1390/10000], Loss: 6.7187\n",
      "Epoch [1400/10000], Loss: 6.3695\n",
      "Epoch [1410/10000], Loss: 14.1383\n",
      "Epoch [1420/10000], Loss: 15.3550\n",
      "Epoch [1430/10000], Loss: 3.5256\n",
      "Epoch [1440/10000], Loss: 5.9419\n",
      "Epoch [1450/10000], Loss: 2.7464\n",
      "Epoch [1460/10000], Loss: 2.7779\n",
      "Epoch [1470/10000], Loss: 8.5391\n",
      "Epoch [1480/10000], Loss: 2.6114\n",
      "Epoch [1490/10000], Loss: 3.8658\n",
      "Epoch [1500/10000], Loss: 5.4443\n",
      "Epoch [1510/10000], Loss: 6.7997\n",
      "Epoch [1520/10000], Loss: 3.2392\n",
      "Epoch [1530/10000], Loss: 2.5300\n",
      "Epoch [1540/10000], Loss: 4.5511\n",
      "Epoch [1550/10000], Loss: 5.7457\n",
      "Epoch [1560/10000], Loss: 1.0031\n",
      "Epoch [1570/10000], Loss: 2.4831\n",
      "Epoch [1580/10000], Loss: 0.4044\n",
      "Epoch [1590/10000], Loss: 9.6949\n",
      "Epoch [1600/10000], Loss: 8.7621\n",
      "Epoch [1610/10000], Loss: 3.6961\n",
      "Epoch [1620/10000], Loss: 3.8158\n",
      "Epoch [1630/10000], Loss: 3.2192\n",
      "Epoch [1640/10000], Loss: 3.8571\n",
      "Epoch [1650/10000], Loss: 3.7519\n",
      "Epoch [1660/10000], Loss: 13.5149\n",
      "Epoch [1670/10000], Loss: 1.4269\n",
      "Epoch [1680/10000], Loss: 2.7056\n",
      "Epoch [1690/10000], Loss: 16.0492\n",
      "Epoch [1700/10000], Loss: 2.2055\n",
      "Epoch [1710/10000], Loss: 3.3256\n",
      "Epoch [1720/10000], Loss: 3.5608\n",
      "Epoch [1730/10000], Loss: 5.2980\n",
      "Epoch [1740/10000], Loss: 3.9905\n",
      "Epoch [1750/10000], Loss: 1.2515\n",
      "Epoch [1760/10000], Loss: 2.5170\n",
      "Epoch [1770/10000], Loss: 12.7006\n",
      "Epoch [1780/10000], Loss: 1.3569\n",
      "Epoch [1790/10000], Loss: 3.0473\n",
      "Epoch [1800/10000], Loss: 5.0287\n",
      "Epoch [1810/10000], Loss: 1.2007\n",
      "Epoch [1820/10000], Loss: 10.3346\n",
      "Epoch [1830/10000], Loss: 2.4412\n",
      "Epoch [1840/10000], Loss: 3.4075\n",
      "Epoch [1850/10000], Loss: 5.3166\n",
      "Epoch [1860/10000], Loss: 3.0260\n",
      "Epoch [1870/10000], Loss: 18.2252\n",
      "Epoch [1880/10000], Loss: 1.1559\n",
      "Epoch [1890/10000], Loss: 2.4338\n",
      "Epoch [1900/10000], Loss: 1.3532\n",
      "Epoch [1910/10000], Loss: 4.7139\n",
      "Epoch [1920/10000], Loss: 4.7127\n",
      "Epoch [1930/10000], Loss: 3.9511\n",
      "Epoch [1940/10000], Loss: 1.9165\n",
      "Epoch [1950/10000], Loss: 1.6818\n",
      "Epoch [1960/10000], Loss: 1.0273\n",
      "Epoch [1970/10000], Loss: 3.4543\n",
      "Epoch [1980/10000], Loss: 3.6872\n",
      "Epoch [1990/10000], Loss: 1.3072\n",
      "Epoch [2000/10000], Loss: 15.7364\n",
      "Epoch [2010/10000], Loss: 5.4441\n",
      "Epoch [2020/10000], Loss: 1.1635\n",
      "Epoch [2030/10000], Loss: 6.8440\n",
      "Epoch [2040/10000], Loss: 11.2688\n",
      "Epoch [2050/10000], Loss: 1.1076\n",
      "Epoch [2060/10000], Loss: 1.4449\n",
      "Epoch [2070/10000], Loss: 0.6180\n",
      "Epoch [2080/10000], Loss: 3.4940\n",
      "Epoch [2090/10000], Loss: 2.0845\n",
      "Epoch [2100/10000], Loss: 2.7586\n",
      "Epoch [2110/10000], Loss: 2.6652\n",
      "Epoch [2120/10000], Loss: 4.3974\n",
      "Epoch [2130/10000], Loss: 2.3520\n",
      "Epoch [2140/10000], Loss: 1.9491\n",
      "Epoch [2150/10000], Loss: 0.6708\n",
      "Epoch [2160/10000], Loss: 1.7022\n",
      "Epoch [2170/10000], Loss: 4.4464\n",
      "Epoch [2180/10000], Loss: 7.2686\n",
      "Epoch [2190/10000], Loss: 1.9578\n",
      "Epoch [2200/10000], Loss: 2.1950\n",
      "Epoch [2210/10000], Loss: 1.1778\n",
      "Epoch [2220/10000], Loss: 6.6189\n",
      "Epoch [2230/10000], Loss: 1.1065\n",
      "Epoch [2240/10000], Loss: 1.5640\n",
      "Epoch [2250/10000], Loss: 2.6364\n",
      "Epoch [2260/10000], Loss: 3.0788\n",
      "Epoch [2270/10000], Loss: 2.9022\n",
      "Epoch [2280/10000], Loss: 3.7159\n",
      "Epoch [2290/10000], Loss: 0.6248\n",
      "Epoch [2300/10000], Loss: 2.3093\n",
      "Epoch [2310/10000], Loss: 1.9550\n",
      "Epoch [2320/10000], Loss: 3.4444\n",
      "Epoch [2330/10000], Loss: 0.8930\n",
      "Epoch [2340/10000], Loss: 2.2670\n",
      "Epoch [2350/10000], Loss: 5.3677\n",
      "Epoch [2360/10000], Loss: 1.6427\n",
      "Epoch [2370/10000], Loss: 2.2426\n",
      "Epoch [2380/10000], Loss: 1.7644\n",
      "Epoch [2390/10000], Loss: 2.6852\n",
      "Epoch [2400/10000], Loss: 1.4064\n",
      "Epoch [2410/10000], Loss: 0.6385\n",
      "Epoch [2420/10000], Loss: 1.5442\n",
      "Epoch [2430/10000], Loss: 1.8274\n",
      "Epoch [2440/10000], Loss: 1.5649\n",
      "Epoch [2450/10000], Loss: 0.6025\n",
      "Epoch [2460/10000], Loss: 3.9436\n",
      "Epoch [2470/10000], Loss: 2.1506\n",
      "Epoch [2480/10000], Loss: 1.3174\n",
      "Epoch [2490/10000], Loss: 4.8541\n",
      "Epoch [2500/10000], Loss: 2.2316\n",
      "Epoch [2510/10000], Loss: 4.2431\n",
      "Epoch [2520/10000], Loss: 2.4071\n",
      "Epoch [2530/10000], Loss: 1.0824\n",
      "Epoch [2540/10000], Loss: 1.4329\n",
      "Epoch [2550/10000], Loss: 6.9328\n",
      "Epoch [2560/10000], Loss: 1.3753\n",
      "Epoch [2570/10000], Loss: 2.5554\n",
      "Epoch [2580/10000], Loss: 3.7424\n",
      "Epoch [2590/10000], Loss: 0.3560\n",
      "Epoch [2600/10000], Loss: 1.6207\n",
      "Epoch [2610/10000], Loss: 3.2947\n",
      "Epoch [2620/10000], Loss: 0.8055\n",
      "Epoch [2630/10000], Loss: 1.0022\n",
      "Epoch [2640/10000], Loss: 1.7642\n",
      "Epoch [2650/10000], Loss: 4.5056\n",
      "Epoch [2660/10000], Loss: 3.1209\n",
      "Epoch [2670/10000], Loss: 2.5572\n",
      "Epoch [2680/10000], Loss: 2.2053\n",
      "Epoch [2690/10000], Loss: 0.4804\n",
      "Epoch [2700/10000], Loss: 1.3366\n",
      "Epoch [2710/10000], Loss: 1.0787\n",
      "Epoch [2720/10000], Loss: 0.8519\n",
      "Epoch [2730/10000], Loss: 0.8045\n",
      "Epoch [2740/10000], Loss: 0.7114\n",
      "Epoch [2750/10000], Loss: 4.6272\n",
      "Epoch [2760/10000], Loss: 1.7177\n",
      "Epoch [2770/10000], Loss: 2.4267\n",
      "Epoch [2780/10000], Loss: 1.3100\n",
      "Epoch [2790/10000], Loss: 8.6156\n",
      "Epoch [2800/10000], Loss: 7.6991\n",
      "Epoch [2810/10000], Loss: 0.8838\n",
      "Epoch [2820/10000], Loss: 0.6399\n",
      "Epoch [2830/10000], Loss: 2.1215\n",
      "Epoch [2840/10000], Loss: 0.6647\n",
      "Epoch [2850/10000], Loss: 1.6015\n",
      "Epoch [2860/10000], Loss: 0.4677\n",
      "Epoch [2870/10000], Loss: 0.3896\n",
      "Epoch [2880/10000], Loss: 0.3938\n",
      "Epoch [2890/10000], Loss: 1.7207\n",
      "Epoch [2900/10000], Loss: 1.9902\n",
      "Epoch [2910/10000], Loss: 3.4728\n",
      "Epoch [2920/10000], Loss: 1.5341\n",
      "Epoch [2930/10000], Loss: 0.8062\n",
      "Epoch [2940/10000], Loss: 0.7579\n",
      "Epoch [2950/10000], Loss: 3.7151\n",
      "Epoch [2960/10000], Loss: 1.7364\n",
      "Epoch [2970/10000], Loss: 0.7671\n",
      "Epoch [2980/10000], Loss: 0.2784\n",
      "Epoch [2990/10000], Loss: 8.2838\n",
      "Epoch [3000/10000], Loss: 0.7511\n",
      "Epoch [3010/10000], Loss: 1.7459\n",
      "Epoch [3020/10000], Loss: 3.1278\n",
      "Epoch [3030/10000], Loss: 1.0132\n",
      "Epoch [3040/10000], Loss: 1.0541\n",
      "Epoch [3050/10000], Loss: 0.4147\n",
      "Epoch [3060/10000], Loss: 7.1867\n",
      "Epoch [3070/10000], Loss: 1.0609\n",
      "Epoch [3080/10000], Loss: 2.2503\n",
      "Epoch [3090/10000], Loss: 1.8150\n",
      "Epoch [3100/10000], Loss: 0.4405\n",
      "Epoch [3110/10000], Loss: 1.6769\n",
      "Epoch [3120/10000], Loss: 11.5460\n",
      "Epoch [3130/10000], Loss: 1.2419\n",
      "Epoch [3140/10000], Loss: 0.6799\n",
      "Epoch [3150/10000], Loss: 1.6837\n",
      "Epoch [3160/10000], Loss: 5.4459\n",
      "Epoch [3170/10000], Loss: 0.7748\n",
      "Epoch [3180/10000], Loss: 2.5176\n",
      "Epoch [3190/10000], Loss: 2.3920\n",
      "Epoch [3200/10000], Loss: 4.6087\n",
      "Epoch [3210/10000], Loss: 4.6362\n",
      "Epoch [3220/10000], Loss: 2.0490\n",
      "Epoch [3230/10000], Loss: 3.2640\n",
      "Epoch [3240/10000], Loss: 1.2755\n",
      "Epoch [3250/10000], Loss: 3.1851\n",
      "Epoch [3260/10000], Loss: 1.3618\n",
      "Epoch [3270/10000], Loss: 3.5832\n",
      "Epoch [3280/10000], Loss: 2.8941\n",
      "Epoch [3290/10000], Loss: 3.1527\n",
      "Epoch [3300/10000], Loss: 1.1400\n",
      "Epoch [3310/10000], Loss: 1.4437\n",
      "Epoch [3320/10000], Loss: 1.4227\n",
      "Epoch [3330/10000], Loss: 0.3212\n",
      "Epoch [3340/10000], Loss: 1.2473\n",
      "Epoch [3350/10000], Loss: 2.8908\n",
      "Epoch [3360/10000], Loss: 1.2983\n",
      "Epoch [3370/10000], Loss: 0.2814\n",
      "Epoch [3380/10000], Loss: 4.3658\n",
      "Epoch [3390/10000], Loss: 0.4743\n",
      "Epoch [3400/10000], Loss: 3.3647\n",
      "Epoch [3410/10000], Loss: 1.2638\n",
      "Epoch [3420/10000], Loss: 1.3136\n",
      "Epoch [3430/10000], Loss: 2.5878\n",
      "Epoch [3440/10000], Loss: 1.5614\n",
      "Epoch [3450/10000], Loss: 0.1953\n",
      "Epoch [3460/10000], Loss: 1.6590\n",
      "Epoch [3470/10000], Loss: 10.9415\n",
      "Epoch [3480/10000], Loss: 3.5127\n",
      "Epoch [3490/10000], Loss: 0.4497\n",
      "Epoch [3500/10000], Loss: 0.1152\n",
      "Epoch [3510/10000], Loss: 0.2915\n",
      "Epoch [3520/10000], Loss: 0.6972\n",
      "Epoch [3530/10000], Loss: 1.0412\n",
      "Epoch [3540/10000], Loss: 10.5156\n",
      "Epoch [3550/10000], Loss: 4.6009\n",
      "Epoch [3560/10000], Loss: 1.6193\n",
      "Epoch [3570/10000], Loss: 2.8571\n",
      "Epoch [3580/10000], Loss: 0.5462\n",
      "Epoch [3590/10000], Loss: 5.7317\n",
      "Epoch [3600/10000], Loss: 1.6577\n",
      "Epoch [3610/10000], Loss: 8.1307\n",
      "Epoch [3620/10000], Loss: 2.1491\n",
      "Epoch [3630/10000], Loss: 1.4153\n",
      "Epoch [3640/10000], Loss: 0.8808\n",
      "Epoch [3650/10000], Loss: 0.5542\n",
      "Epoch [3660/10000], Loss: 0.9493\n",
      "Epoch [3670/10000], Loss: 1.8316\n",
      "Epoch [3680/10000], Loss: 0.2527\n",
      "Epoch [3690/10000], Loss: 3.2156\n",
      "Epoch [3700/10000], Loss: 0.4669\n",
      "Epoch [3710/10000], Loss: 3.9109\n",
      "Epoch [3720/10000], Loss: 2.4998\n",
      "Epoch [3730/10000], Loss: 0.5462\n",
      "Epoch [3740/10000], Loss: 1.5767\n",
      "Epoch [3750/10000], Loss: 0.6127\n",
      "Epoch [3760/10000], Loss: 1.4304\n",
      "Epoch [3770/10000], Loss: 8.4457\n",
      "Epoch [3780/10000], Loss: 3.1376\n",
      "Epoch [3790/10000], Loss: 1.3933\n",
      "Epoch [3800/10000], Loss: 0.3820\n",
      "Epoch [3810/10000], Loss: 0.4846\n",
      "Epoch [3820/10000], Loss: 0.6680\n",
      "Epoch [3830/10000], Loss: 5.1809\n",
      "Epoch [3840/10000], Loss: 0.2913\n",
      "Epoch [3850/10000], Loss: 1.0706\n",
      "Epoch [3860/10000], Loss: 2.8226\n",
      "Epoch [3870/10000], Loss: 3.8961\n",
      "Epoch [3880/10000], Loss: 0.6855\n",
      "Epoch [3890/10000], Loss: 0.3233\n",
      "Epoch [3900/10000], Loss: 0.3178\n",
      "Epoch [3910/10000], Loss: 0.3368\n",
      "Epoch [3920/10000], Loss: 2.7347\n",
      "Epoch [3930/10000], Loss: 2.9147\n",
      "Epoch [3940/10000], Loss: 1.1315\n",
      "Epoch [3950/10000], Loss: 0.5060\n",
      "Epoch [3960/10000], Loss: 5.9411\n",
      "Epoch [3970/10000], Loss: 2.3109\n",
      "Epoch [3980/10000], Loss: 0.9304\n",
      "Epoch [3990/10000], Loss: 0.4464\n",
      "Epoch [4000/10000], Loss: 3.7495\n",
      "Epoch [4010/10000], Loss: 1.5973\n",
      "Epoch [4020/10000], Loss: 2.3986\n",
      "Epoch [4030/10000], Loss: 1.0093\n",
      "Epoch [4040/10000], Loss: 0.8781\n",
      "Epoch [4050/10000], Loss: 1.6073\n",
      "Epoch [4060/10000], Loss: 0.5486\n",
      "Epoch [4070/10000], Loss: 0.6965\n",
      "Epoch [4080/10000], Loss: 1.0051\n",
      "Epoch [4090/10000], Loss: 1.2499\n",
      "Epoch [4100/10000], Loss: 0.4757\n",
      "Epoch [4110/10000], Loss: 0.4375\n",
      "Epoch [4120/10000], Loss: 0.2740\n",
      "Epoch [4130/10000], Loss: 0.5297\n",
      "Epoch [4140/10000], Loss: 0.8229\n",
      "Epoch [4150/10000], Loss: 3.6223\n",
      "Epoch [4160/10000], Loss: 3.4855\n",
      "Epoch [4170/10000], Loss: 2.3916\n",
      "Epoch [4180/10000], Loss: 8.5943\n",
      "Epoch [4190/10000], Loss: 0.5383\n",
      "Epoch [4200/10000], Loss: 1.3786\n",
      "Epoch [4210/10000], Loss: 0.3706\n",
      "Epoch [4220/10000], Loss: 9.6490\n",
      "Epoch [4230/10000], Loss: 0.3783\n",
      "Epoch [4240/10000], Loss: 0.1046\n",
      "Epoch [4250/10000], Loss: 0.4404\n",
      "Epoch [4260/10000], Loss: 8.8762\n",
      "Epoch [4270/10000], Loss: 2.6861\n",
      "Epoch [4280/10000], Loss: 7.4309\n",
      "Epoch [4290/10000], Loss: 3.3836\n",
      "Epoch [4300/10000], Loss: 3.8299\n",
      "Epoch [4310/10000], Loss: 1.6119\n",
      "Epoch [4320/10000], Loss: 1.6149\n",
      "Epoch [4330/10000], Loss: 3.1619\n",
      "Epoch [4340/10000], Loss: 6.3076\n",
      "Epoch [4350/10000], Loss: 9.7826\n",
      "Epoch [4360/10000], Loss: 0.2826\n",
      "Epoch [4370/10000], Loss: 2.4031\n",
      "Epoch [4380/10000], Loss: 0.8090\n",
      "Epoch [4390/10000], Loss: 0.2919\n",
      "Epoch [4400/10000], Loss: 1.7653\n",
      "Epoch [4410/10000], Loss: 0.9390\n",
      "Epoch [4420/10000], Loss: 0.0522\n",
      "Epoch [4430/10000], Loss: 1.0170\n",
      "Epoch [4440/10000], Loss: 3.0478\n",
      "Epoch [4450/10000], Loss: 3.8800\n",
      "Epoch [4460/10000], Loss: 0.8766\n",
      "Epoch [4470/10000], Loss: 0.3409\n",
      "Epoch [4480/10000], Loss: 0.4313\n",
      "Epoch [4490/10000], Loss: 1.0823\n",
      "Epoch [4500/10000], Loss: 0.3782\n",
      "Epoch [4510/10000], Loss: 11.3277\n",
      "Epoch [4520/10000], Loss: 0.9565\n",
      "Epoch [4530/10000], Loss: 0.4289\n",
      "Epoch [4540/10000], Loss: 1.8134\n",
      "Epoch [4550/10000], Loss: 0.3967\n",
      "Epoch [4560/10000], Loss: 0.5605\n",
      "Epoch [4570/10000], Loss: 0.1489\n",
      "Epoch [4580/10000], Loss: 0.4862\n",
      "Epoch [4590/10000], Loss: 7.5181\n",
      "Epoch [4600/10000], Loss: 13.1775\n",
      "Epoch [4610/10000], Loss: 3.9332\n",
      "Epoch [4620/10000], Loss: 0.4517\n",
      "Epoch [4630/10000], Loss: 0.4049\n",
      "Epoch [4640/10000], Loss: 0.5481\n",
      "Epoch [4650/10000], Loss: 1.1962\n",
      "Epoch [4660/10000], Loss: 0.7211\n",
      "Epoch [4670/10000], Loss: 1.6195\n",
      "Epoch [4680/10000], Loss: 1.1377\n",
      "Epoch [4690/10000], Loss: 0.2916\n",
      "Epoch [4700/10000], Loss: 1.2671\n",
      "Epoch [4710/10000], Loss: 0.1946\n",
      "Epoch [4720/10000], Loss: 1.0422\n",
      "Epoch [4730/10000], Loss: 0.4603\n",
      "Epoch [4740/10000], Loss: 0.2261\n",
      "Epoch [4750/10000], Loss: 0.6171\n",
      "Epoch [4760/10000], Loss: 0.4971\n",
      "Epoch [4770/10000], Loss: 0.3904\n",
      "Epoch [4780/10000], Loss: 1.0431\n",
      "Epoch [4790/10000], Loss: 0.7660\n",
      "Epoch [4800/10000], Loss: 1.0885\n",
      "Epoch [4810/10000], Loss: 7.1913\n",
      "Epoch [4820/10000], Loss: 0.7609\n",
      "Epoch [4830/10000], Loss: 0.3258\n",
      "Epoch [4840/10000], Loss: 4.2937\n",
      "Epoch [4850/10000], Loss: 1.5573\n",
      "Epoch [4860/10000], Loss: 1.5910\n",
      "Epoch [4870/10000], Loss: 3.8438\n",
      "Epoch [4880/10000], Loss: 0.3002\n",
      "Epoch [4890/10000], Loss: 0.8638\n",
      "Epoch [4900/10000], Loss: 0.7997\n",
      "Epoch [4910/10000], Loss: 0.8428\n",
      "Epoch [4920/10000], Loss: 1.1801\n",
      "Epoch [4930/10000], Loss: 0.0804\n",
      "Epoch [4940/10000], Loss: 2.9039\n",
      "Epoch [4950/10000], Loss: 4.1277\n",
      "Epoch [4960/10000], Loss: 3.1298\n",
      "Epoch [4970/10000], Loss: 0.6025\n",
      "Epoch [4980/10000], Loss: 1.7621\n",
      "Epoch [4990/10000], Loss: 0.3091\n",
      "Epoch [5000/10000], Loss: 0.5795\n",
      "Epoch [5010/10000], Loss: 0.2419\n",
      "Epoch [5020/10000], Loss: 0.4482\n",
      "Epoch [5030/10000], Loss: 2.2087\n",
      "Epoch [5040/10000], Loss: 0.3674\n",
      "Epoch [5050/10000], Loss: 0.4996\n",
      "Epoch [5060/10000], Loss: 0.4766\n",
      "Epoch [5070/10000], Loss: 1.4342\n",
      "Epoch [5080/10000], Loss: 0.3361\n",
      "Epoch [5090/10000], Loss: 1.7050\n",
      "Epoch [5100/10000], Loss: 0.5486\n",
      "Epoch [5110/10000], Loss: 0.5280\n",
      "Epoch [5120/10000], Loss: 6.7311\n",
      "Epoch [5130/10000], Loss: 1.3785\n",
      "Epoch [5140/10000], Loss: 0.9079\n",
      "Epoch [5150/10000], Loss: 0.9942\n",
      "Epoch [5160/10000], Loss: 1.3225\n",
      "Epoch [5170/10000], Loss: 2.4388\n",
      "Epoch [5180/10000], Loss: 0.7312\n",
      "Epoch [5190/10000], Loss: 0.5962\n",
      "Epoch [5200/10000], Loss: 2.3319\n",
      "Epoch [5210/10000], Loss: 3.1036\n",
      "Epoch [5220/10000], Loss: 2.0084\n",
      "Epoch [5230/10000], Loss: 3.0938\n",
      "Epoch [5240/10000], Loss: 1.7399\n",
      "Epoch [5250/10000], Loss: 0.5044\n",
      "Epoch [5260/10000], Loss: 2.0640\n",
      "Epoch [5270/10000], Loss: 5.2105\n",
      "Epoch [5280/10000], Loss: 1.4948\n",
      "Epoch [5290/10000], Loss: 4.5172\n",
      "Epoch [5300/10000], Loss: 8.6297\n",
      "Epoch [5310/10000], Loss: 0.5132\n",
      "Epoch [5320/10000], Loss: 2.4086\n",
      "Epoch [5330/10000], Loss: 3.9353\n",
      "Epoch [5340/10000], Loss: 1.1612\n",
      "Epoch [5350/10000], Loss: 7.5592\n",
      "Epoch [5360/10000], Loss: 0.6529\n",
      "Epoch [5370/10000], Loss: 1.9912\n",
      "Epoch [5380/10000], Loss: 1.8094\n",
      "Epoch [5390/10000], Loss: 0.6382\n",
      "Epoch [5400/10000], Loss: 0.1587\n",
      "Epoch [5410/10000], Loss: 0.2628\n",
      "Epoch [5420/10000], Loss: 0.4509\n",
      "Epoch [5430/10000], Loss: 4.8700\n",
      "Epoch [5440/10000], Loss: 3.1982\n",
      "Epoch [5450/10000], Loss: 1.4068\n",
      "Epoch [5460/10000], Loss: 0.7991\n",
      "Epoch [5470/10000], Loss: 13.5295\n",
      "Epoch [5480/10000], Loss: 0.8061\n",
      "Epoch [5490/10000], Loss: 0.6256\n",
      "Epoch [5500/10000], Loss: 0.4220\n",
      "Epoch [5510/10000], Loss: 0.2410\n",
      "Epoch [5520/10000], Loss: 1.5507\n",
      "Epoch [5530/10000], Loss: 0.2444\n",
      "Epoch [5540/10000], Loss: 0.3189\n",
      "Epoch [5550/10000], Loss: 8.6403\n",
      "Epoch [5560/10000], Loss: 0.3818\n",
      "Epoch [5570/10000], Loss: 1.1871\n",
      "Epoch [5580/10000], Loss: 0.2380\n",
      "Epoch [5590/10000], Loss: 1.2278\n",
      "Epoch [5600/10000], Loss: 1.4364\n",
      "Epoch [5610/10000], Loss: 0.6680\n",
      "Epoch [5620/10000], Loss: 0.3252\n",
      "Epoch [5630/10000], Loss: 0.3552\n",
      "Epoch [5640/10000], Loss: 0.9327\n",
      "Epoch [5650/10000], Loss: 6.3040\n",
      "Epoch [5660/10000], Loss: 1.8760\n",
      "Epoch [5670/10000], Loss: 12.5927\n",
      "Epoch [5680/10000], Loss: 0.1118\n",
      "Epoch [5690/10000], Loss: 0.3826\n",
      "Epoch [5700/10000], Loss: 0.2844\n",
      "Epoch [5710/10000], Loss: 3.3342\n",
      "Epoch [5720/10000], Loss: 3.4730\n",
      "Epoch [5730/10000], Loss: 0.5932\n",
      "Epoch [5740/10000], Loss: 0.5954\n",
      "Epoch [5750/10000], Loss: 0.1293\n",
      "Epoch [5760/10000], Loss: 2.7119\n",
      "Epoch [5770/10000], Loss: 9.7516\n",
      "Epoch [5780/10000], Loss: 1.8938\n",
      "Epoch [5790/10000], Loss: 1.2823\n",
      "Epoch [5800/10000], Loss: 0.2525\n",
      "Epoch [5810/10000], Loss: 2.2437\n",
      "Epoch [5820/10000], Loss: 0.1476\n",
      "Epoch [5830/10000], Loss: 1.1483\n",
      "Epoch [5840/10000], Loss: 1.4619\n",
      "Epoch [5850/10000], Loss: 0.0797\n",
      "Epoch [5860/10000], Loss: 1.7676\n",
      "Epoch [5870/10000], Loss: 0.9969\n",
      "Epoch [5880/10000], Loss: 0.8435\n",
      "Epoch [5890/10000], Loss: 2.5392\n",
      "Epoch [5900/10000], Loss: 2.3930\n",
      "Epoch [5910/10000], Loss: 1.5321\n",
      "Epoch [5920/10000], Loss: 0.7969\n",
      "Epoch [5930/10000], Loss: 0.8517\n",
      "Epoch [5940/10000], Loss: 2.5024\n",
      "Epoch [5950/10000], Loss: 1.0565\n",
      "Epoch [5960/10000], Loss: 0.3984\n",
      "Epoch [5970/10000], Loss: 0.3394\n",
      "Epoch [5980/10000], Loss: 0.6711\n",
      "Epoch [5990/10000], Loss: 1.7220\n",
      "Epoch [6000/10000], Loss: 0.4098\n",
      "Epoch [6010/10000], Loss: 1.2691\n",
      "Epoch [6020/10000], Loss: 0.9146\n",
      "Epoch [6030/10000], Loss: 2.3216\n",
      "Epoch [6040/10000], Loss: 0.7347\n",
      "Epoch [6050/10000], Loss: 0.5625\n",
      "Epoch [6060/10000], Loss: 2.0837\n",
      "Epoch [6070/10000], Loss: 1.7727\n",
      "Epoch [6080/10000], Loss: 0.1328\n",
      "Epoch [6090/10000], Loss: 0.3495\n",
      "Epoch [6100/10000], Loss: 5.5788\n",
      "Epoch [6110/10000], Loss: 0.9283\n",
      "Epoch [6120/10000], Loss: 0.6056\n",
      "Epoch [6130/10000], Loss: 0.2307\n",
      "Epoch [6140/10000], Loss: 3.0469\n",
      "Epoch [6150/10000], Loss: 0.2057\n",
      "Epoch [6160/10000], Loss: 1.4774\n",
      "Epoch [6170/10000], Loss: 0.4779\n",
      "Epoch [6180/10000], Loss: 0.9251\n",
      "Epoch [6190/10000], Loss: 0.2654\n",
      "Epoch [6200/10000], Loss: 0.1058\n",
      "Epoch [6210/10000], Loss: 0.3726\n",
      "Epoch [6220/10000], Loss: 0.7903\n",
      "Epoch [6230/10000], Loss: 10.3956\n",
      "Epoch [6240/10000], Loss: 1.3422\n",
      "Epoch [6250/10000], Loss: 2.1358\n",
      "Epoch [6260/10000], Loss: 1.0167\n",
      "Epoch [6270/10000], Loss: 0.2330\n",
      "Epoch [6280/10000], Loss: 0.1961\n",
      "Epoch [6290/10000], Loss: 0.4978\n",
      "Epoch [6300/10000], Loss: 0.5448\n",
      "Epoch [6310/10000], Loss: 0.6416\n",
      "Epoch [6320/10000], Loss: 0.4677\n",
      "Epoch [6330/10000], Loss: 1.4654\n",
      "Epoch [6340/10000], Loss: 0.1776\n",
      "Epoch [6350/10000], Loss: 0.3985\n",
      "Epoch [6360/10000], Loss: 0.6220\n",
      "Epoch [6370/10000], Loss: 0.3598\n",
      "Epoch [6380/10000], Loss: 0.7635\n",
      "Epoch [6390/10000], Loss: 0.8404\n",
      "Epoch [6400/10000], Loss: 0.2611\n",
      "Epoch [6410/10000], Loss: 2.1417\n",
      "Epoch [6420/10000], Loss: 3.0020\n",
      "Epoch [6430/10000], Loss: 0.5203\n",
      "Epoch [6440/10000], Loss: 0.2523\n",
      "Epoch [6450/10000], Loss: 0.8453\n",
      "Epoch [6460/10000], Loss: 2.8702\n",
      "Epoch [6470/10000], Loss: 0.3759\n",
      "Epoch [6480/10000], Loss: 0.3760\n",
      "Epoch [6490/10000], Loss: 0.5977\n",
      "Epoch [6500/10000], Loss: 4.0646\n",
      "Epoch [6510/10000], Loss: 6.5417\n",
      "Epoch [6520/10000], Loss: 0.4023\n",
      "Epoch [6530/10000], Loss: 10.5535\n",
      "Epoch [6540/10000], Loss: 0.4797\n",
      "Epoch [6550/10000], Loss: 3.8956\n",
      "Epoch [6560/10000], Loss: 0.9684\n",
      "Epoch [6570/10000], Loss: 0.5559\n",
      "Epoch [6580/10000], Loss: 0.1151\n",
      "Epoch [6590/10000], Loss: 0.3528\n",
      "Epoch [6600/10000], Loss: 0.5274\n",
      "Epoch [6610/10000], Loss: 2.7559\n",
      "Epoch [6620/10000], Loss: 1.7535\n",
      "Epoch [6630/10000], Loss: 0.4529\n",
      "Epoch [6640/10000], Loss: 0.9909\n",
      "Epoch [6650/10000], Loss: 0.2753\n",
      "Epoch [6660/10000], Loss: 0.7537\n",
      "Epoch [6670/10000], Loss: 0.1869\n",
      "Epoch [6680/10000], Loss: 0.8548\n",
      "Epoch [6690/10000], Loss: 0.2099\n",
      "Epoch [6700/10000], Loss: 0.3357\n",
      "Epoch [6710/10000], Loss: 2.1115\n",
      "Epoch [6720/10000], Loss: 1.0542\n",
      "Epoch [6730/10000], Loss: 0.1672\n",
      "Epoch [6740/10000], Loss: 0.4135\n",
      "Epoch [6750/10000], Loss: 1.0033\n",
      "Epoch [6760/10000], Loss: 1.8467\n",
      "Epoch [6770/10000], Loss: 0.4972\n",
      "Epoch [6780/10000], Loss: 1.0087\n",
      "Epoch [6790/10000], Loss: 0.2992\n",
      "Epoch [6800/10000], Loss: 2.0909\n",
      "Epoch [6810/10000], Loss: 0.8318\n",
      "Epoch [6820/10000], Loss: 0.1173\n",
      "Epoch [6830/10000], Loss: 0.5076\n",
      "Epoch [6840/10000], Loss: 3.6507\n",
      "Epoch [6850/10000], Loss: 0.4969\n",
      "Epoch [6860/10000], Loss: 0.5894\n",
      "Epoch [6870/10000], Loss: 2.3231\n",
      "Epoch [6880/10000], Loss: 1.0354\n",
      "Epoch [6890/10000], Loss: 0.3275\n",
      "Epoch [6900/10000], Loss: 1.6139\n",
      "Epoch [6910/10000], Loss: 3.6767\n",
      "Epoch [6920/10000], Loss: 0.4525\n",
      "Epoch [6930/10000], Loss: 1.6712\n",
      "Epoch [6940/10000], Loss: 3.4024\n",
      "Epoch [6950/10000], Loss: 0.8500\n",
      "Epoch [6960/10000], Loss: 0.2083\n",
      "Epoch [6970/10000], Loss: 1.8104\n",
      "Epoch [6980/10000], Loss: 0.4474\n",
      "Epoch [6990/10000], Loss: 7.1489\n",
      "Epoch [7000/10000], Loss: 0.7775\n",
      "Epoch [7010/10000], Loss: 5.4471\n",
      "Epoch [7020/10000], Loss: 2.0601\n",
      "Epoch [7030/10000], Loss: 0.0383\n",
      "Epoch [7040/10000], Loss: 0.7397\n",
      "Epoch [7050/10000], Loss: 0.1715\n",
      "Epoch [7060/10000], Loss: 0.5465\n",
      "Epoch [7070/10000], Loss: 0.0677\n",
      "Epoch [7080/10000], Loss: 0.4941\n",
      "Epoch [7090/10000], Loss: 0.1603\n",
      "Epoch [7100/10000], Loss: 1.7040\n",
      "Epoch [7110/10000], Loss: 0.8868\n",
      "Epoch [7120/10000], Loss: 0.0806\n",
      "Epoch [7130/10000], Loss: 0.1262\n",
      "Epoch [7140/10000], Loss: 0.8205\n",
      "Epoch [7150/10000], Loss: 7.4382\n",
      "Epoch [7160/10000], Loss: 0.6060\n",
      "Epoch [7170/10000], Loss: 0.2731\n",
      "Epoch [7180/10000], Loss: 3.5587\n",
      "Epoch [7190/10000], Loss: 0.4047\n",
      "Epoch [7200/10000], Loss: 0.0891\n",
      "Epoch [7210/10000], Loss: 8.3727\n",
      "Epoch [7220/10000], Loss: 4.4278\n",
      "Epoch [7230/10000], Loss: 1.8455\n",
      "Epoch [7240/10000], Loss: 0.3795\n",
      "Epoch [7250/10000], Loss: 0.8197\n",
      "Epoch [7260/10000], Loss: 0.2501\n",
      "Epoch [7270/10000], Loss: 0.4305\n",
      "Epoch [7280/10000], Loss: 0.5860\n",
      "Epoch [7290/10000], Loss: 0.3299\n",
      "Epoch [7300/10000], Loss: 0.3385\n",
      "Epoch [7310/10000], Loss: 3.7468\n",
      "Epoch [7320/10000], Loss: 0.4878\n",
      "Epoch [7330/10000], Loss: 1.3855\n",
      "Epoch [7340/10000], Loss: 1.0387\n",
      "Epoch [7350/10000], Loss: 0.8152\n",
      "Epoch [7360/10000], Loss: 0.9512\n",
      "Epoch [7370/10000], Loss: 0.1970\n",
      "Epoch [7380/10000], Loss: 4.3065\n",
      "Epoch [7390/10000], Loss: 1.1492\n",
      "Epoch [7400/10000], Loss: 0.9092\n",
      "Epoch [7410/10000], Loss: 0.0597\n",
      "Epoch [7420/10000], Loss: 0.0525\n",
      "Epoch [7430/10000], Loss: 0.2701\n",
      "Epoch [7440/10000], Loss: 0.2069\n",
      "Epoch [7450/10000], Loss: 0.7501\n",
      "Epoch [7460/10000], Loss: 3.3136\n",
      "Epoch [7470/10000], Loss: 8.6842\n",
      "Epoch [7480/10000], Loss: 9.7288\n",
      "Epoch [7490/10000], Loss: 0.3459\n",
      "Epoch [7500/10000], Loss: 3.0856\n",
      "Epoch [7510/10000], Loss: 0.2361\n",
      "Epoch [7520/10000], Loss: 0.2973\n",
      "Epoch [7530/10000], Loss: 0.9590\n",
      "Epoch [7540/10000], Loss: 0.7152\n",
      "Epoch [7550/10000], Loss: 0.5542\n",
      "Epoch [7560/10000], Loss: 1.3561\n",
      "Epoch [7570/10000], Loss: 0.2718\n",
      "Epoch [7580/10000], Loss: 2.4490\n",
      "Epoch [7590/10000], Loss: 0.8600\n",
      "Epoch [7600/10000], Loss: 0.8640\n",
      "Epoch [7610/10000], Loss: 0.2561\n",
      "Epoch [7620/10000], Loss: 0.5894\n",
      "Epoch [7630/10000], Loss: 0.8121\n",
      "Epoch [7640/10000], Loss: 0.5161\n",
      "Epoch [7650/10000], Loss: 0.0759\n",
      "Epoch [7660/10000], Loss: 2.3519\n",
      "Epoch [7670/10000], Loss: 0.7784\n",
      "Epoch [7680/10000], Loss: 2.2896\n",
      "Epoch [7690/10000], Loss: 0.6312\n",
      "Epoch [7700/10000], Loss: 0.5843\n",
      "Epoch [7710/10000], Loss: 1.4240\n",
      "Epoch [7720/10000], Loss: 0.4146\n",
      "Epoch [7730/10000], Loss: 0.2278\n",
      "Epoch [7740/10000], Loss: 0.2240\n",
      "Epoch [7750/10000], Loss: 0.0978\n",
      "Epoch [7760/10000], Loss: 1.0550\n",
      "Epoch [7770/10000], Loss: 0.2531\n",
      "Epoch [7780/10000], Loss: 0.2942\n",
      "Epoch [7790/10000], Loss: 0.2138\n",
      "Epoch [7800/10000], Loss: 7.2010\n",
      "Epoch [7810/10000], Loss: 0.6533\n",
      "Epoch [7820/10000], Loss: 0.6986\n",
      "Epoch [7830/10000], Loss: 1.3931\n",
      "Epoch [7840/10000], Loss: 1.5533\n",
      "Epoch [7850/10000], Loss: 0.2615\n",
      "Epoch [7860/10000], Loss: 0.9983\n",
      "Epoch [7870/10000], Loss: 0.2672\n",
      "Epoch [7880/10000], Loss: 0.2572\n",
      "Epoch [7890/10000], Loss: 0.5983\n",
      "Epoch [7900/10000], Loss: 0.2396\n",
      "Epoch [7910/10000], Loss: 1.3925\n",
      "Epoch [7920/10000], Loss: 0.2874\n",
      "Epoch [7930/10000], Loss: 1.2191\n",
      "Epoch [7940/10000], Loss: 0.4042\n",
      "Epoch [7950/10000], Loss: 2.3211\n",
      "Epoch [7960/10000], Loss: 0.3110\n",
      "Epoch [7970/10000], Loss: 0.6122\n",
      "Epoch [7980/10000], Loss: 3.3443\n",
      "Epoch [7990/10000], Loss: 3.1689\n",
      "Epoch [8000/10000], Loss: 1.0209\n",
      "Epoch [8010/10000], Loss: 0.4498\n",
      "Epoch [8020/10000], Loss: 0.1510\n",
      "Epoch [8030/10000], Loss: 0.6454\n",
      "Epoch [8040/10000], Loss: 3.6834\n",
      "Epoch [8050/10000], Loss: 3.0133\n",
      "Epoch [8060/10000], Loss: 0.4813\n",
      "Epoch [8070/10000], Loss: 0.8682\n",
      "Epoch [8080/10000], Loss: 0.4310\n",
      "Epoch [8090/10000], Loss: 0.2440\n",
      "Epoch [8100/10000], Loss: 7.1080\n",
      "Epoch [8110/10000], Loss: 0.1968\n",
      "Epoch [8120/10000], Loss: 0.1473\n",
      "Epoch [8130/10000], Loss: 3.5567\n",
      "Epoch [8140/10000], Loss: 0.3600\n",
      "Epoch [8150/10000], Loss: 0.1661\n",
      "Epoch [8160/10000], Loss: 6.3530\n",
      "Epoch [8170/10000], Loss: 0.2310\n",
      "Epoch [8180/10000], Loss: 1.0702\n",
      "Epoch [8190/10000], Loss: 0.3879\n",
      "Epoch [8200/10000], Loss: 0.4055\n",
      "Epoch [8210/10000], Loss: 0.2060\n",
      "Epoch [8220/10000], Loss: 1.9792\n",
      "Epoch [8230/10000], Loss: 0.2405\n",
      "Epoch [8240/10000], Loss: 0.5843\n",
      "Epoch [8250/10000], Loss: 0.4129\n",
      "Epoch [8260/10000], Loss: 1.0981\n",
      "Epoch [8270/10000], Loss: 3.4907\n",
      "Epoch [8280/10000], Loss: 0.8922\n",
      "Epoch [8290/10000], Loss: 0.2678\n",
      "Epoch [8300/10000], Loss: 0.5240\n",
      "Epoch [8310/10000], Loss: 1.0900\n",
      "Epoch [8320/10000], Loss: 0.6453\n",
      "Epoch [8330/10000], Loss: 2.6920\n",
      "Epoch [8340/10000], Loss: 1.2418\n",
      "Epoch [8350/10000], Loss: 0.4910\n",
      "Epoch [8360/10000], Loss: 1.8852\n",
      "Epoch [8370/10000], Loss: 2.9685\n",
      "Epoch [8380/10000], Loss: 1.0564\n",
      "Epoch [8390/10000], Loss: 0.1055\n",
      "Epoch [8400/10000], Loss: 2.6881\n",
      "Epoch [8410/10000], Loss: 0.3451\n",
      "Epoch [8420/10000], Loss: 0.1198\n",
      "Epoch [8430/10000], Loss: 0.0712\n",
      "Epoch [8440/10000], Loss: 0.1661\n",
      "Epoch [8450/10000], Loss: 0.3246\n",
      "Epoch [8460/10000], Loss: 7.6594\n",
      "Epoch [8470/10000], Loss: 1.4155\n",
      "Epoch [8480/10000], Loss: 0.3008\n",
      "Epoch [8490/10000], Loss: 0.9169\n",
      "Epoch [8500/10000], Loss: 0.4993\n",
      "Epoch [8510/10000], Loss: 2.7052\n",
      "Epoch [8520/10000], Loss: 0.4709\n",
      "Epoch [8530/10000], Loss: 0.5744\n",
      "Epoch [8540/10000], Loss: 0.2259\n",
      "Epoch [8550/10000], Loss: 0.6977\n",
      "Epoch [8560/10000], Loss: 0.1677\n",
      "Epoch [8570/10000], Loss: 0.8748\n",
      "Epoch [8580/10000], Loss: 0.7167\n",
      "Epoch [8590/10000], Loss: 0.2410\n",
      "Epoch [8600/10000], Loss: 0.1367\n",
      "Epoch [8610/10000], Loss: 1.4807\n",
      "Epoch [8620/10000], Loss: 0.3074\n",
      "Epoch [8630/10000], Loss: 0.2042\n",
      "Epoch [8640/10000], Loss: 0.2097\n",
      "Epoch [8650/10000], Loss: 0.3507\n",
      "Epoch [8660/10000], Loss: 0.6618\n",
      "Epoch [8670/10000], Loss: 0.6672\n",
      "Epoch [8680/10000], Loss: 1.8007\n",
      "Epoch [8690/10000], Loss: 1.3889\n",
      "Epoch [8700/10000], Loss: 1.5985\n",
      "Epoch [8710/10000], Loss: 2.0718\n",
      "Epoch [8720/10000], Loss: 0.1396\n",
      "Epoch [8730/10000], Loss: 0.1644\n",
      "Epoch [8740/10000], Loss: 0.1250\n",
      "Epoch [8750/10000], Loss: 0.1566\n",
      "Epoch [8760/10000], Loss: 1.5458\n",
      "Epoch [8770/10000], Loss: 2.0352\n",
      "Epoch [8780/10000], Loss: 0.2437\n",
      "Epoch [8790/10000], Loss: 5.3956\n",
      "Epoch [8800/10000], Loss: 0.8662\n",
      "Epoch [8810/10000], Loss: 7.1107\n",
      "Epoch [8820/10000], Loss: 0.0842\n",
      "Epoch [8830/10000], Loss: 1.9435\n",
      "Epoch [8840/10000], Loss: 0.3271\n",
      "Epoch [8850/10000], Loss: 0.9046\n",
      "Epoch [8860/10000], Loss: 6.1078\n",
      "Epoch [8870/10000], Loss: 0.0888\n",
      "Epoch [8880/10000], Loss: 0.1235\n",
      "Epoch [8890/10000], Loss: 1.4677\n",
      "Epoch [8900/10000], Loss: 0.2826\n",
      "Epoch [8910/10000], Loss: 0.0893\n",
      "Epoch [8920/10000], Loss: 0.1008\n",
      "Epoch [8930/10000], Loss: 2.8328\n",
      "Epoch [8940/10000], Loss: 0.4397\n",
      "Epoch [8950/10000], Loss: 1.1428\n",
      "Epoch [8960/10000], Loss: 0.3946\n",
      "Epoch [8970/10000], Loss: 0.0957\n",
      "Epoch [8980/10000], Loss: 1.7407\n",
      "Epoch [8990/10000], Loss: 3.6703\n",
      "Epoch [9000/10000], Loss: 0.0830\n",
      "Epoch [9010/10000], Loss: 0.6877\n",
      "Epoch [9020/10000], Loss: 0.3892\n",
      "Epoch [9030/10000], Loss: 0.1302\n",
      "Epoch [9040/10000], Loss: 0.8449\n",
      "Epoch [9050/10000], Loss: 2.1487\n",
      "Epoch [9060/10000], Loss: 1.1131\n",
      "Epoch [9070/10000], Loss: 0.2959\n",
      "Epoch [9080/10000], Loss: 0.3738\n",
      "Epoch [9090/10000], Loss: 0.7409\n",
      "Epoch [9100/10000], Loss: 0.6015\n",
      "Epoch [9110/10000], Loss: 0.1230\n",
      "Epoch [9120/10000], Loss: 0.9780\n",
      "Epoch [9130/10000], Loss: 5.9455\n",
      "Epoch [9140/10000], Loss: 6.7914\n",
      "Epoch [9150/10000], Loss: 1.6717\n",
      "Epoch [9160/10000], Loss: 0.4562\n",
      "Epoch [9170/10000], Loss: 2.8850\n",
      "Epoch [9180/10000], Loss: 4.0313\n",
      "Epoch [9190/10000], Loss: 0.1649\n",
      "Epoch [9200/10000], Loss: 0.5655\n",
      "Epoch [9210/10000], Loss: 0.1507\n",
      "Epoch [9220/10000], Loss: 2.8434\n",
      "Epoch [9230/10000], Loss: 0.4587\n",
      "Epoch [9240/10000], Loss: 1.4202\n",
      "Epoch [9250/10000], Loss: 0.5656\n",
      "Epoch [9260/10000], Loss: 0.5373\n",
      "Epoch [9270/10000], Loss: 6.1747\n",
      "Epoch [9280/10000], Loss: 0.4162\n",
      "Epoch [9290/10000], Loss: 0.0888\n",
      "Epoch [9300/10000], Loss: 0.3037\n",
      "Epoch [9310/10000], Loss: 0.1321\n",
      "Epoch [9320/10000], Loss: 0.4747\n",
      "Epoch [9330/10000], Loss: 0.2428\n",
      "Epoch [9340/10000], Loss: 0.4759\n",
      "Epoch [9350/10000], Loss: 4.5315\n",
      "Epoch [9360/10000], Loss: 0.0893\n",
      "Epoch [9370/10000], Loss: 1.5905\n",
      "Epoch [9380/10000], Loss: 0.8774\n",
      "Epoch [9390/10000], Loss: 2.9972\n",
      "Epoch [9400/10000], Loss: 2.9064\n",
      "Epoch [9410/10000], Loss: 0.3685\n",
      "Epoch [9420/10000], Loss: 1.8235\n",
      "Epoch [9430/10000], Loss: 3.0050\n",
      "Epoch [9440/10000], Loss: 0.4515\n",
      "Epoch [9450/10000], Loss: 3.0736\n",
      "Epoch [9460/10000], Loss: 1.3309\n",
      "Epoch [9470/10000], Loss: 0.6218\n",
      "Epoch [9480/10000], Loss: 0.5681\n",
      "Epoch [9490/10000], Loss: 0.0928\n",
      "Epoch [9500/10000], Loss: 0.5865\n",
      "Epoch [9510/10000], Loss: 2.3473\n",
      "Epoch [9520/10000], Loss: 0.9530\n",
      "Epoch [9530/10000], Loss: 0.3767\n",
      "Epoch [9540/10000], Loss: 0.5325\n",
      "Epoch [9550/10000], Loss: 0.1349\n",
      "Epoch [9560/10000], Loss: 0.0496\n",
      "Epoch [9570/10000], Loss: 0.2303\n",
      "Epoch [9580/10000], Loss: 0.7076\n",
      "Epoch [9590/10000], Loss: 0.1104\n",
      "Epoch [9600/10000], Loss: 0.3470\n",
      "Epoch [9610/10000], Loss: 2.0058\n",
      "Epoch [9620/10000], Loss: 3.2160\n",
      "Epoch [9630/10000], Loss: 0.2180\n",
      "Epoch [9640/10000], Loss: 5.5448\n",
      "Epoch [9650/10000], Loss: 0.2829\n",
      "Epoch [9660/10000], Loss: 1.5464\n",
      "Epoch [9670/10000], Loss: 8.9039\n",
      "Epoch [9680/10000], Loss: 3.7317\n",
      "Epoch [9690/10000], Loss: 0.3670\n",
      "Epoch [9700/10000], Loss: 0.7868\n",
      "Epoch [9710/10000], Loss: 0.2981\n",
      "Epoch [9720/10000], Loss: 0.6922\n",
      "Epoch [9730/10000], Loss: 4.9510\n",
      "Epoch [9740/10000], Loss: 3.0610\n",
      "Epoch [9750/10000], Loss: 0.4168\n",
      "Epoch [9760/10000], Loss: 1.0681\n",
      "Epoch [9770/10000], Loss: 0.0755\n",
      "Epoch [9780/10000], Loss: 0.1023\n",
      "Epoch [9790/10000], Loss: 0.0755\n",
      "Epoch [9800/10000], Loss: 0.2375\n",
      "Epoch [9810/10000], Loss: 1.4012\n",
      "Epoch [9820/10000], Loss: 7.5586\n",
      "Epoch [9830/10000], Loss: 3.3352\n",
      "Epoch [9840/10000], Loss: 4.1687\n",
      "Epoch [9850/10000], Loss: 0.8889\n",
      "Epoch [9860/10000], Loss: 4.4552\n",
      "Epoch [9870/10000], Loss: 1.2817\n",
      "Epoch [9880/10000], Loss: 1.8252\n",
      "Epoch [9890/10000], Loss: 2.4689\n",
      "Epoch [9900/10000], Loss: 0.3082\n",
      "Epoch [9910/10000], Loss: 1.9735\n",
      "Epoch [9920/10000], Loss: 1.7372\n",
      "Epoch [9930/10000], Loss: 0.0548\n",
      "Epoch [9940/10000], Loss: 0.5674\n",
      "Epoch [9950/10000], Loss: 0.2809\n",
      "Epoch [9960/10000], Loss: 0.1412\n",
      "Epoch [9970/10000], Loss: 0.2611\n",
      "Epoch [9980/10000], Loss: 0.3121\n",
      "Epoch [9990/10000], Loss: 0.6028\n",
      "Epoch [10000/10000], Loss: 0.1555\n",
      "Test Loss: 67.2351\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = pd.read_csv(\"data/Real_estate.csv\")\n",
    "\n",
    "X = data[['X1 transaction date', 'X2 house age', 'X3 distance to the nearest MRT station', \n",
    "          'X4 number of convenience stores', 'X5 latitude', 'X6 longitude']]\n",
    "y = data['Y house price of unit area']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# define the neural network structure\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(6, 30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30, 20),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 20),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 1)\n",
    ")\n",
    "\n",
    "# define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# training loop\n",
    "num_epochs = 10000\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, targets in train_loader:\n",
    "        # forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# evaluate on test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor)\n",
    "    test_loss = criterion(test_outputs, y_test_tensor)\n",
    "    print(f'Test Loss: {test_loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### (b) How many hidden layers does your MLP model have? How many units does each hidden layer have?\n",
    "\n",
    "3 hidden layers. 30 units, 20 units, and 20 units repectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) What is your learning rate? What is your batch size? How many training epochs did you have?\n",
    "\n",
    "Learning rate = 0.001\n",
    "\n",
    "Batch size = 32\n",
    "\n",
    "number of epochs = 10,000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) How many parameters does your MLP model have? Why? Show me the calculation process.\n",
    "\n",
    "Input layer to first input layer:\n",
    "$6 \\times 30 + 30 = 210$ parameters\n",
    "\n",
    "First to second hidden layer:\n",
    "$30 \\times 20 + 20 = 600$ parameters\n",
    "\n",
    "First to second hidden layer:\n",
    "$20 \\times 20 + 20 = 420$ parameters\n",
    "\n",
    "Third hidden layer output layer:\n",
    "$20 \\times 1 + 1 = 21$ parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (e) Is your trained model better than, the same with, or worse than the Multiple Linear Regression solution you had from your previous homework submission? Why?\n",
    "\n",
    "<span style=\"color: red\">TODO</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take the “MNIST.ipynb\" as a start point:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Execute the given code using torch and nn.Sequential model to train a neural network. What is your testing accuracy? (Just tell me a number, no need to show the code, this is for your own convenience to make sure you can run the code)\n",
    "\n",
    "Accuracy of the model on the test images: 93.94%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Modify the code to train the same model with the test data, and evaluate the accuracy using the training data. What is your accuracy? Show me your modifications (i.e., only the lines of programs that are different from my given code).\n",
    "\n",
    "```\n",
    "# Training loop\n",
    "for epoch in range(10):  # train for 10 epochs\n",
    "    for images, labels in test_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = loss_fn(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Testing loop\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        output = model(images)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "```\n",
    "\n",
    "Accuracy of the model on the test images: 86.98%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Consider the following modification of the data set: for every hand written digit image, suppose the corresponding digit is \\( i \\in \\{0, . . . , 9\\}\\), change its label (y) to \\( i \\% 2 \\) (i.e., \\( \\text{mod} (i, 2)\\))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Show me your code that modifies y_train and y_test to align with the data set modifications.\n",
    "\n",
    "``` \n",
    "def read_images_labels(self, images_filepath, labels_filepath):        \n",
    "        labels = []\n",
    "        with open(labels_filepath, 'rb') as file:\n",
    "            magic, size = struct.unpack(\">II\", file.read(8))\n",
    "            if magic != 2049:\n",
    "                raise ValueError('Magic number mismatch, expected 2049, got {}'.format(magic))\n",
    "            labels = np.fromfile(file, dtype=np.uint8) \n",
    "\n",
    "        labels = labels % 2      \n",
    "        \n",
    "        with open(images_filepath, 'rb') as file:\n",
    "            magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "            if magic != 2051:\n",
    "                raise ValueError('Magic number mismatch, expected 2051, got {}'.format(magic))\n",
    "            image_data = array(\"B\", file.read())        \n",
    "        images = []\n",
    "        for i in range(size):\n",
    "            images.append([0] * rows * cols)\n",
    "        for i in range(size):\n",
    "            img = np.array(image_data[i * rows * cols:(i + 1) * rows * cols])\n",
    "            img = img.reshape(28, 28)\n",
    "            images[i][:] = img            \n",
    "        \n",
    "        return images, labels\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Using the same MLP provided in the “MNIST.ipynb\", what minimum change should you make to have the model work with the modified data set (i.e., what is your number of outputs)?\n",
    "\n",
    "Change the number of outputs to 2 rather then 10.\n",
    "\n",
    "```\n",
    "model = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(28*28, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 2)  # 10 classes for MNIST digits\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - What are the one hot encoded outcomes of the labels in the modified data set?\n",
    "\n",
    "Label 0 (even) becomes: $[0,1]$\n",
    "\n",
    "Label 1 (odd) becomes: $[1,0]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) Modify your train data set such that there are only 10 images left with the label being 3, and 10 images left with the label being 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Show me your code that makes the above modification.\n",
    "\n",
    "```\n",
    "def read_images_labels(self, images_filepath, labels_filepath):        \n",
    "        labels = []\n",
    "        with open(labels_filepath, 'rb') as file:\n",
    "            magic, size = struct.unpack(\">II\", file.read(8))\n",
    "            if magic != 2049:\n",
    "                raise ValueError('Magic number mismatch, expected 2049, got {}'.format(magic))\n",
    "            labels = np.fromfile(file, dtype=np.uint8) \n",
    "\n",
    "        labels = labels % 2\n",
    "        \n",
    "        # last 10 are 9 and 10 before that are 3 for labels\n",
    "        if labels_filepath is self.training_labels_filepath:\n",
    "            labels[-20:-10] = 3\n",
    "            labels[-10] = 9\n",
    "        \n",
    "        with open(images_filepath, 'rb') as file:\n",
    "            magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "            if magic != 2051:\n",
    "                raise ValueError('Magic number mismatch, expected 2051, got {}'.format(magic))\n",
    "            image_data = array(\"B\", file.read())        \n",
    "        images = []\n",
    "        for i in range(size):\n",
    "            images.append([0] * rows * cols)\n",
    "        for i in range(size):\n",
    "            img = np.array(image_data[i * rows * cols:(i + 1) * rows * cols])\n",
    "            img = img.reshape(28, 28)\n",
    "            images[i][:] = img            \n",
    "        \n",
    "        return images, labels```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Using the same MLP provided in the “MNIST.ipynb\", and train the model with the modified data set. Evaluate your model’s performance with the testing data set. Your model should be performing worse than the original model. Describe what changes you could make to improve the model’s performance given the modified data set? Undoing your above data set modifications cannot be a solution. Do not include your code, but you are welcome to use experiments or other analyses to help deriving your answer to this question.\n",
    "\n",
    "<span style=\"color: red\">TODO</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. (Required for 574, optional for 474) Consider the following data set for scalar input x and scalar output y:\n",
    "\n",
    "| i | 1 | 2 | 3 | 4 |\n",
    "|---|---|---|---|---|\n",
    "| \\(x_i\\) | -1 | 1 | 3 | 5 |\n",
    "| \\(y_i\\) | 0 | 0 | 1 | 0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Design a 2-layer feed-forward Neural Network (one hidden layer and one output layer, each layer has a linear transform followed by an activation function to be defined later) with \\($d_H = 2$\\) hidden units and \\($d_o = 1$\\) output unit that produces \\($u_o(x_i) = y_i$\\) on all four presented data points. Use\n",
    "\n",
    "\\[ $g_H(z)$ = $g_o(z)$ = $\\begin{cases} 1 & \\text{if } z \\geq 0 \\\\ 0 & \\text{if } z < 0 \\end{cases}$ \\]\n",
    "\n",
    "What are the weights (\\($\\omega_H$\\) and \\($\\omega_o$\\)) and biases (\\($b_H$\\) and \\($b_o$\\)) used in each layer such that the neural network output \\($u_o(x_i) = y_i$\\) for all \\($i \\in$ \\{1, 2, 3, 4\\}\\) ?\n",
    "\n",
    "<span style=\"color: red\">FINISH</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input 1: x = -1, Hidden output: [0 1], Network output: 0, Target: 0\n",
      "Input 2: x = 1, Hidden output: [1 1], Network output: 0, Target: 0\n",
      "Input 3: x = 3, Hidden output: [1 0], Network output: 1, Target: 1\n",
      "Input 4: x = 5, Hidden output: [1 0], Network output: 1, Target: 0\n"
     ]
    }
   ],
   "source": [
    "# Step activation function\n",
    "def step_function(z):\n",
    "    return np.where(z >= 0, 1, 0)\n",
    "\n",
    "# Define the forward pass of the network\n",
    "def forward_pass(x, w_H, b_H, w_o, b_o):\n",
    "    # Calculate hidden layer output\n",
    "    h = step_function(np.dot(w_H, x) + b_H)\n",
    "    # Calculate output layer result\n",
    "    u_o = step_function(np.dot(w_o, h) + b_o)\n",
    "    return u_o, h\n",
    "\n",
    "# Input data points and target outputs\n",
    "data = [\n",
    "    (-1, 0),\n",
    "    (1, 0),\n",
    "    (3, 1),\n",
    "    (5, 0)\n",
    "]\n",
    "\n",
    "# Convert inputs to array for computation\n",
    "x_vals = np.array([x for x, _ in data]).reshape(-1, 1)\n",
    "y_vals = np.array([y for _, y in data])\n",
    "\n",
    "# Initialize weights and biases (can be manually set or tuned)\n",
    "w_H = np.array([[1], [-1]])  # Weights for hidden layer (2x1)\n",
    "b_H = np.array([0.5, 1])       # Biases for hidden layer (2)\n",
    "w_o = np.array([1, -1])      # Weights for output layer (1x2)\n",
    "b_o = -0.5                     # Bias for output layer (scalar)\n",
    "\n",
    "# Forward pass and check outputs\n",
    "for i, (x, target) in enumerate(data):\n",
    "    x_input = np.array([x])  # Input as an array\n",
    "    output, h = forward_pass(x_input, w_H, b_H, w_o, b_o)\n",
    "    print(f\"Input {i+1}: x = {x}, Hidden output: {h}, Network output: {output}, Target: {target}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Take the “MNIST-CNN.ipynb” and “MNIST-ResNet.ipynb” as your start point:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Build a customized data set, \\(D\\), with labels of only two digits (e.g., images with labels of only 1 and 3). Pick a data set size that aligns with your computational capability. Show me your code. Plot a subset of your customized data set.\n",
    "\n",
    "```\n",
    "def read_images_labels(self, images_filepath, labels_filepath):        \n",
    "        labels = []\n",
    "        with open(labels_filepath, 'rb') as file:\n",
    "            magic, size = struct.unpack(\">II\", file.read(8))\n",
    "            if magic != 2049:\n",
    "                raise ValueError('Magic number mismatch, expected 2049, got {}'.format(magic))\n",
    "            labels = array(\"B\", file.read())        \n",
    "        \n",
    "        with open(images_filepath, 'rb') as file:\n",
    "            magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "            if magic != 2051:\n",
    "                raise ValueError('Magic number mismatch, expected 2051, got {}'.format(magic))\n",
    "            image_data = array(\"B\", file.read())        \n",
    "        images = []\n",
    "        for i in range(size):\n",
    "            images.append([0] * rows * cols)\n",
    "        for i in range(size):\n",
    "            img = np.array(image_data[i * rows * cols:(i + 1) * rows * cols])\n",
    "            img = img.reshape(28, 28)\n",
    "            images[i][:] = img            \n",
    "        \n",
    "        filtered_images = []\n",
    "        filtered_labels = []\n",
    "        for img, label in zip(images, labels):\n",
    "            if label in [1, 3]:\n",
    "                filtered_images.append(img)\n",
    "                filtered_labels.append(label)\n",
    "        \n",
    "        return filtered_images, filtered_labels```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Train a CNN model with \\(D\\). Sweep the data set once (i.e., with 1 epoch) with your choice of batch size, optimizer, and other configurations. Show me your code.\n",
    "\n",
    "```\n",
    "class MnistDataloader(object):\n",
    "    def __init__(self, training_images_filepath,training_labels_filepath,\n",
    "                 test_images_filepath, test_labels_filepath):\n",
    "        self.training_images_filepath = training_images_filepath\n",
    "        self.training_labels_filepath = training_labels_filepath\n",
    "        self.test_images_filepath = test_images_filepath\n",
    "        self.test_labels_filepath = test_labels_filepath\n",
    "    \n",
    "    def read_images_labels(self, images_filepath, labels_filepath):        \n",
    "        labels = []\n",
    "        with open(labels_filepath, 'rb') as file:\n",
    "            magic, size = struct.unpack(\">II\", file.read(8))\n",
    "            if magic != 2049:\n",
    "                raise ValueError('Magic number mismatch, expected 2049, got {}'.format(magic))\n",
    "            labels = array(\"B\", file.read())        \n",
    "        \n",
    "        with open(images_filepath, 'rb') as file:\n",
    "            magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "            if magic != 2051:\n",
    "                raise ValueError('Magic number mismatch, expected 2051, got {}'.format(magic))\n",
    "            image_data = array(\"B\", file.read())        \n",
    "        images = []\n",
    "        for i in range(size):\n",
    "            images.append([0] * rows * cols)\n",
    "        for i in range(size):\n",
    "            img = np.array(image_data[i * rows * cols:(i + 1) * rows * cols])\n",
    "            img = img.reshape(28, 28)\n",
    "            images[i][:] = img            \n",
    "        \n",
    "        filtered_images = []\n",
    "        filtered_labels = []\n",
    "        for img, label in zip(images, labels):\n",
    "            if label in [1, 3]:\n",
    "                filtered_images.append(img)\n",
    "                filtered_labels.append(label)\n",
    "        \n",
    "        return filtered_images, filtered_labels\n",
    "\n",
    "        # return images, labels\n",
    "            \n",
    "    def load_data(self):\n",
    "        x_train, y_train = self.read_images_labels(self.training_images_filepath, self.training_labels_filepath)\n",
    "        x_test, y_test = self.read_images_labels(self.test_images_filepath, self.test_labels_filepath)\n",
    "        return (x_train, y_train),(x_test, y_test)  \n",
    "\n",
    "# Set file paths based on added MNIST Datasets\n",
    "training_images_filepath = 'data/mnist-dataset/train-images.idx3-ubyte'\n",
    "training_labels_filepath = 'data/mnist-dataset/train-labels.idx1-ubyte'\n",
    "test_images_filepath = 'data/mnist-dataset/t10k-images.idx3-ubyte'\n",
    "test_labels_filepath = 'data/mnist-dataset/t10k-labels.idx1-ubyte'\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "train_images_tensor = torch.tensor(x_train, dtype=torch.float) / 255.0  # Normalize\n",
    "train_labels_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "test_images_tensor = torch.tensor(x_test, dtype=torch.float) / 255.0  # Normalize\n",
    "test_labels_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(train_images_tensor.unsqueeze(1), train_labels_tensor)  # Add channel dimension\n",
    "test_dataset = TensorDataset(test_images_tensor.unsqueeze(1), test_labels_tensor)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Assuming train_loader and test_loader are defined elsewhere\n",
    "\n",
    "\n",
    "# Define a simple CNN\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.dropout = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(1024, 128) # After flattening the conv layers, adjust the size accordingly\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = x.view(-1, 1024) # Flatten the tensor for the fully connected layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    print (\"mps is available\")\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "model = Net().to(device)\n",
    "\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1):  # train for 10 epochs\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "\n",
    "# Testing loop - Calculate accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        output = model(images)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy of the model on the test images: {accuracy * 100:.2f}%')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Using the same data loader and train-test split, train a ResNet model with \\(D\\). Sweep the data set once (i.e., with 1 epoch) with your choice of batch size, optimizer, and other configurations. Show me your code.\n",
    "\n",
    "```\n",
    "class MnistDataloader(object):\n",
    "    def __init__(self, training_images_filepath,training_labels_filepath,\n",
    "                 test_images_filepath, test_labels_filepath):\n",
    "        self.training_images_filepath = training_images_filepath\n",
    "        self.training_labels_filepath = training_labels_filepath\n",
    "        self.test_images_filepath = test_images_filepath\n",
    "        self.test_labels_filepath = test_labels_filepath\n",
    "    \n",
    "    def read_images_labels(self, images_filepath, labels_filepath):        \n",
    "        labels = []\n",
    "        with open(labels_filepath, 'rb') as file:\n",
    "            magic, size = struct.unpack(\">II\", file.read(8))\n",
    "            if magic != 2049:\n",
    "                raise ValueError('Magic number mismatch, expected 2049, got {}'.format(magic))\n",
    "            labels = array(\"B\", file.read())        \n",
    "        \n",
    "        with open(images_filepath, 'rb') as file:\n",
    "            magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "            if magic != 2051:\n",
    "                raise ValueError('Magic number mismatch, expected 2051, got {}'.format(magic))\n",
    "            image_data = array(\"B\", file.read())        \n",
    "        images = []\n",
    "        for i in range(size):\n",
    "            images.append([0] * rows * cols)\n",
    "        for i in range(size):\n",
    "            img = np.array(image_data[i * rows * cols:(i + 1) * rows * cols])\n",
    "            img = img.reshape(28, 28)\n",
    "            images[i][:] = img            \n",
    "        \n",
    "        filtered_images = []\n",
    "        filtered_labels = []\n",
    "        for img, label in zip(images, labels):\n",
    "            if label in [1, 3]:\n",
    "                filtered_images.append(img)\n",
    "                filtered_labels.append(label)\n",
    "        \n",
    "        return filtered_images, filtered_labels\n",
    "\n",
    "        # return images, labels\n",
    "            \n",
    "    def load_data(self):\n",
    "        x_train, y_train = self.read_images_labels(self.training_images_filepath, self.training_labels_filepath)\n",
    "        x_test, y_test = self.read_images_labels(self.test_images_filepath, self.test_labels_filepath)\n",
    "        return (x_train, y_train),(x_test, y_test)  \n",
    "\n",
    "# Set file paths based on added MNIST Datasets\n",
    "training_images_filepath = 'data/mnist-dataset/train-images.idx3-ubyte'\n",
    "training_labels_filepath = 'data/mnist-dataset/train-labels.idx1-ubyte'\n",
    "test_images_filepath = 'data/mnist-dataset/t10k-images.idx3-ubyte'\n",
    "test_labels_filepath = 'data/mnist-dataset/t10k-labels.idx1-ubyte'\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "train_images_tensor = torch.tensor(x_train, dtype=torch.float) / 255.0  # Normalize\n",
    "train_labels_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "test_images_tensor = torch.tensor(x_test, dtype=torch.float) / 255.0  # Normalize\n",
    "test_labels_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(train_images_tensor.unsqueeze(1), train_labels_tensor)  # Add channel dimension\n",
    "test_dataset = TensorDataset(test_images_tensor.unsqueeze(1), test_labels_tensor)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class SmallResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(SmallResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.linear = nn.Linear(128*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = F.avg_pool2d(out, out.size()[3])\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) Using the same data loader and train-test split, train a Feedforward Neural Network (NN) model with \\(D\\). Sweep the data set once (i.e., with 1 epoch) with your choice of batch size, optimizer, and other configurations. Show me your code.\n",
    "\n",
    "<span style=\"color: red\">TODO</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Consider a CNN layer with the following characteristics:\n",
    "\n",
    "   - Input volume size: 32x32x3 (where 32x32 is the spatial dimension of the input, and 3 is the number of input channels, e.g., RGB image)\n",
    "   - Number of conv kernels: 10\n",
    "   - Kernel size: 5×5\n",
    "   - Stride: 1\n",
    "   - Padding: 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) How many parameters does the above model have?\n",
    "\n",
    "Number of parameters per ach convolutional kernel:\n",
    "$$5 \\times 5 \\times 3 = 75$$\n",
    "\n",
    "Number of parameters for all kernels:\n",
    "$$75 \\times 10 = 750$$\n",
    "\n",
    "Eahc kernel has a bias term therefore the total number of parameters is:\n",
    "$$750 + 10 = 760 \\text{ parameters}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) What is the minimum size of the image that still allows the above model to remain functional and compatible?\n",
    "\n",
    "$\\bold{5 \\times 5}$, because the kernel size is $5 \\times 5$ pixels, and the it must fit the kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. What is the key problem that ResNet aims to address in deep neural networks?\n",
    "\n",
    "ResNet addresses the problem of training very deep neural networks by introducing residual connections, which help mitigate issues like the vanishing gradient problem and the degradation problem. These skip connections allow gradients to flow more easily through the network during backpropagation, making it easier to train deep models and preventing performance degradation as more layers are added."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. What is the key problem that dropout aims to address in deep neural networks?\n",
    "\n",
    "Dropout aims to address **overfitting**. It does so by randomly dropping neurons so that the network does not fully rely on any certain neurons."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coms5740",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
